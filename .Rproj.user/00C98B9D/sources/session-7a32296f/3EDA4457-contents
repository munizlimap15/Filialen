# Branch Clustering Analysis
# 12/April/2024
# DS challenge JÖ - Pedro Lima (pedrohe@gmail.com)

# Libraries
library(readxl) 
library(dplyr)  
library(ggplot2)
library(sf)
library(corrplot)

setwd("C:/Users/pedro/Desktop/JO_bonus")

source("Geo_code.R")

# --------------------------------------------------------
# My understanding (so far about the data)
# Filialdaten.xlsx contains a summary of  products (classes) per each associated store.

# $ FILIALE                                         Unique identifier for each branch.
# $ B_LAND                                          Country code where the branch is located.
# $ VERKAUFS_M2                                     Sales area of the branch in square meters.
# $ Revenue                                         Total sales revenue generated by the branch.
# $ Kund. Anz.                                      Number of customers who visited the branch.
# $ Aktionsanteil                                   Proportion of sales from promotional items.
# $ Anteil Clever                                   Proportion of sales from 'Clever' brand products.
# $ Anteil Ja!Natürlich                             Proportion of sales from 'Ja!Natürlich' products.
# $ Anteil Feinkost                                 Proportion of sales from deli (fine food) products.
# $ Anteil Obst&Gemüse                              Proportion of sales from fruits and vegetables.
# $ Anteil BILLA Marke                              Proportion of sales from 'BILLA' brand products.
# $ Anteil BILLA Corso                              Proportion of sales from 'BILLA Corso' premium line.
# $ Anteil Getränke ohne Alkohol                    Proportion of sales from non-alcoholic beverages.
# $ Anteil Alkohol                                  Proportion of sales from alcoholic beverages.
# $ ANZAHL_Verbrauchermärkte_im Umkreis von 20min   Number of consumer markets within a 20-minute radius.
# $ ANZAHL_Diskonter_im Umkreis von 20min           Number of discount stores within a 20-minute radius.
# $ KaufKraft_Drogeriefachhandel_KOPF               Per capita purchasing power for drugstore products.
# $ KaufKraft_Lebensmittelhandel_KOPF               Per capita purchasing power for grocery products.
# $ Kaufkraft_KOPF                                  Overall per capita purchasing power.


n_distinct(merged_data$FILIALE) # Filials. Since it is the same row as the df, can be used as ID if necessary. 
n_distinct(merged_data$B_LAND) #9, possibly due to the 9 federal states in Austria. 

median_revenue_by_state <- merged_data %>%
  group_by(State) %>%
  summarise(MedianRevenue = median(Revenue, na.rm = TRUE))  # Calculate median, removing NA values
# --------------------------------------------------------
# Exploratory Data Analysis 
# Getting the first insights of the given data.
# summaries, distributions, and potential insights (correlations).

# Using actual histograms to show distribution of sales per state
ggplot(merged_data) +
  aes(x = "", y = Revenue) +
  geom_violin(adjust = 1, scale = "area", fill = "#112446", alpha=0.5, color="white") +
  #theme_minimal() +
  facet_wrap(vars(State))


# Correlation Matrix Plot
numeric_data <- select(merged_data, where(is.numeric), 
                       -Rnk, -B_LAND, -PPI) 
numeric_data$geometry= NULL
# I will replace NA by a simple median of the column. Which is wrong by essence, but this is just an excercise anyways.
for(i in seq_along(numeric_data)) {
  if(is.numeric(numeric_data[[i]])) {
    numeric_data[[i]][is.na(numeric_data[[i]])] <- median(numeric_data[[i]], na.rm = TRUE)
  }
}
correlations <- cor(numeric_data, use = "everything")

corrplot(correlations, 
         method="circle",
         diag=FALSE,type="upper", order="hclust",addCoef.col = "black")

# --------------------------------------------------------
# Feature Engineering
# Create new features and scale/normalize data as required for clustering.

# Creating new features like sales per square meter
merged_data$sales_per_m2 <- merged_data$Revenue / merged_data$VERKAUFS_M2

# Standardizing numerical features
merged_data[, sapply(merged_data, is.numeric)] <- scale(merged_data[, sapply(merged_data, is.numeric)])

# --------------------------------------------------------
# Clustering
# Choose the clustering algorithm, determine the number of clusters, and perform clustering.

# Choosing K-means clustering and determining the number of clusters with the elbow method
set.seed(123)  # for reproducibility
library(cluster)
wss <- (nrow(merged_data)-1)*sum(apply(merged_data, 2, var))
for (i in 2:15) wss[i] <- sum(kmeans(merged_data, centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")

# Performing K-means clustering
kmeans_result <- kmeans(merged_data, centers=4)

# --------------------------------------------------------
# Insights and Recommendations
# Analyze clusters to derive insights and make business recommendations.

# Analyzing cluster characteristics
print("Cluster Analysis:")
table(merged_data$FILIALE, kmeans_result$cluster)

# --------------------------------------------------------
# Presentation Strategy
# Prepare for presentation to different audiences.

# Example visualization for non-analytics department
library(ggplot2)
ggplot(merged_data, aes(x=factor(kmeans_result$cluster), fill=factor(kmeans_result$cluster))) +
  geom_bar() +
  labs(title="Branch Clusters", x="Cluster", y="Count")


